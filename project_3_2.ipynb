{
 "metadata": {
  "name": "",
  "signature": "sha256:bfbc8e0a8b6cd71da7953fbf26f897043e6af1c0f358b899ac8d0112f7bccb9a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Cluster class for Module 3\n",
      "\"\"\"\n",
      "\n",
      "import math\n",
      "import random\n",
      "import urllib2\n",
      "\n",
      "class Cluster:\n",
      "    \"\"\"\n",
      "    Class for creating and merging clusters of counties\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, fips_codes, horiz_pos, vert_pos, population, risk):\n",
      "        \"\"\"\n",
      "        Create a cluster based the models a set of counties' data\n",
      "        \"\"\"\n",
      "        self._fips_codes = fips_codes\n",
      "        self._horiz_center = horiz_pos\n",
      "        self._vert_center = vert_pos\n",
      "        self._total_population = population\n",
      "        self._averaged_risk = risk\n",
      "        \n",
      "        \n",
      "    def __repr__(self):\n",
      "        \"\"\"\n",
      "        String representation assuming the module is \"alg_cluster\".\n",
      "        \"\"\"\n",
      "        rep = \"alg_cluster.Cluster(\"\n",
      "        rep += str(self._fips_codes) + \", \"\n",
      "        rep += str(self._horiz_center) + \", \"\n",
      "        rep += str(self._vert_center) + \", \"\n",
      "        rep += str(self._total_population) + \", \"\n",
      "        rep += str(self._averaged_risk) + \")\"\n",
      "        return rep\n",
      "\n",
      "\n",
      "    def fips_codes(self):\n",
      "        \"\"\"\n",
      "        Get the cluster's set of FIPS codes\n",
      "        \"\"\"\n",
      "        return self._fips_codes\n",
      "    \n",
      "    def horiz_center(self):\n",
      "        \"\"\"\n",
      "        Get the averged horizontal center of cluster\n",
      "        \"\"\"\n",
      "        return self._horiz_center\n",
      "    \n",
      "    def vert_center(self):\n",
      "        \"\"\"\n",
      "        Get the averaged vertical center of the cluster\n",
      "        \"\"\"\n",
      "        return self._vert_center\n",
      "    \n",
      "    def total_population(self):\n",
      "        \"\"\"\n",
      "        Get the total population for the cluster\n",
      "        \"\"\"\n",
      "        return self._total_population\n",
      "    \n",
      "    def averaged_risk(self):\n",
      "        \"\"\"\n",
      "        Get the averaged risk for the cluster\n",
      "        \"\"\"\n",
      "        return self._averaged_risk\n",
      "   \n",
      "        \n",
      "    def copy(self):\n",
      "        \"\"\"\n",
      "        Return a copy of a cluster\n",
      "        \"\"\"\n",
      "        copy_cluster = Cluster(set(self._fips_codes), self._horiz_center, self._vert_center,\n",
      "                               self._total_population, self._averaged_risk)\n",
      "        return copy_cluster\n",
      "\n",
      "\n",
      "    def distance(self, other_cluster):\n",
      "        \"\"\"\n",
      "        Compute the Euclidean distance between two clusters\n",
      "        \"\"\"\n",
      "        vert_dist = self._vert_center - other_cluster.vert_center()\n",
      "        horiz_dist = self._horiz_center - other_cluster.horiz_center()\n",
      "        return math.sqrt(vert_dist ** 2 + horiz_dist ** 2)\n",
      "        \n",
      "    def merge_clusters(self, other_cluster):\n",
      "        \"\"\"\n",
      "        Merge one cluster into another\n",
      "        The merge uses the relatively populations of each\n",
      "        cluster in computing a new center and risk\n",
      "        \n",
      "        Note that this method mutates self\n",
      "        \"\"\"\n",
      "        if len(other_cluster.fips_codes()) == 0:\n",
      "            return self\n",
      "        else:\n",
      "            self._fips_codes.update(set(other_cluster.fips_codes()))\n",
      " \n",
      "            # compute weights for averaging\n",
      "            self_weight = float(self._total_population)                        \n",
      "            other_weight = float(other_cluster.total_population())\n",
      "            self._total_population = self._total_population + other_cluster.total_population()\n",
      "            self_weight /= self._total_population\n",
      "            other_weight /= self._total_population\n",
      "                    \n",
      "            # update center and risk using weights\n",
      "            self._vert_center = self_weight * self._vert_center + other_weight * other_cluster.vert_center()\n",
      "            self._horiz_center = self_weight * self._horiz_center + other_weight * other_cluster.horiz_center()\n",
      "            self._averaged_risk = self_weight * self._averaged_risk + other_weight * other_cluster.averaged_risk()\n",
      "            return self\n",
      "\n",
      "    def cluster_error(self, data_table):\n",
      "        \"\"\"\n",
      "        Input: data_table is the original table of cancer data used in creating the cluster.\n",
      "        \n",
      "        Output: The error as the sum of the square of the distance from each county\n",
      "        in the cluster to the cluster center (weighted by its population)\n",
      "        \"\"\"\n",
      "        # Build hash table to accelerate error computation\n",
      "        fips_to_line = {}\n",
      "        for line_idx in range(len(data_table)):\n",
      "            line = data_table[line_idx]\n",
      "            fips_to_line[line[0]] = line_idx\n",
      "        \n",
      "        # compute error as weighted squared distance from counties to cluster center\n",
      "        total_error = 0\n",
      "        counties = self.fips_codes()\n",
      "        for county in counties:\n",
      "            line = data_table[fips_to_line[county]]\n",
      "            singleton_cluster = Cluster(set([line[0]]), line[1], line[2], line[3], line[4])\n",
      "            singleton_distance = self.distance(singleton_cluster)\n",
      "            total_error += (singleton_distance ** 2) * singleton_cluster.total_population()\n",
      "        return total_error\n",
      "\n",
      "def pair_distance(cluster_list, idx1, idx2):\n",
      "    \"\"\"\n",
      "    Helper function to compute Euclidean distance between two clusters\n",
      "    in cluster_list with indices idx1 and idx2\n",
      "    \n",
      "    Returns tuple (dist, idx1, idx2) with idx1 < idx2 where dist is distance between\n",
      "    cluster_list[idx1] and cluster_list[idx2]\n",
      "    \"\"\"\n",
      "    return (cluster_list[idx1].distance(cluster_list[idx2]), idx1, idx2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bf_closest_pair_indices(cluster_list, indices):\n",
      "    \"\"\"Brute-force algorithm for defining closest clusters. Returns set of closest clusters.\n",
      "    \"\"\"\n",
      "    min_distance = -1\n",
      "    closest_pair = set()\n",
      "    for index1 in indices:\n",
      "        for index2 in indices:\n",
      "            if index1 >= index2:\n",
      "                continue\n",
      "            if min_distance == -1:\n",
      "                min_distance = cluster_list[index1].distance(cluster_list[index2])\n",
      "                closest_pair.add((min_distance, index1, index2))\n",
      "            elif min_distance == cluster_list[index1].distance(cluster_list[index2]):\n",
      "                closest_pair.add((min_distance, index1, index2))\n",
      "            elif min_distance > cluster_list[index1].distance(cluster_list[index2]):\n",
      "                min_distance = cluster_list[index1].distance(cluster_list[index2])\n",
      "                closest_pair = set()\n",
      "                closest_pair.add((min_distance, index1, index2))\n",
      "    return closest_pair  \n",
      "\n",
      "def slow_closest_pairs(cluster_list):\n",
      "    \"\"\"Calls brute force method with a default clusters list\n",
      "    \"\"\"\n",
      "    return bf_closest_pair_indices(cluster_list, range(len(cluster_list)))\n",
      "\n",
      "def slow_closest_pair_helper(cluster_list, indices):\n",
      "    \"\"\"Recursively called helper for slow_closest_pairs\n",
      "    \"\"\"\n",
      "    if len(indices) <= 3:\n",
      "        return bf_closest_pair_indices(cluster_list, indices)\n",
      "\n",
      "    half_of_clusters = int(math.ceil(float(len(indices)) / 2))\n",
      "    mid_horiz_coordinate = (cluster_list[indices[half_of_clusters-1]].horiz_center() + cluster_list[indices[half_of_clusters]].horiz_center())*0.5\n",
      "    \n",
      "    left_closest_pairs = slow_closest_pair_helper(cluster_list, indices[:half_of_clusters])\n",
      "    right_closest_pairs = slow_closest_pair_helper(cluster_list, indices[half_of_clusters:])   \n",
      "    \n",
      "    # choosing min in both halfes\n",
      "    if random.sample(left_closest_pairs, 1)[0] < random.sample(right_closest_pairs, 1)[0]:\n",
      "        min_distance = random.sample(left_closest_pairs, 1)[0]\n",
      "        result = left_closest_pairs\n",
      "    elif random.sample(left_closest_pairs, 1)[0] > random.sample(right_closest_pairs, 1)[0]:\n",
      "        min_distance = random.sample(right_closest_pairs, 1)[0]\n",
      "        result = right_closest_pairs\n",
      "    else:\n",
      "        min_distance = random.sample(left_closest_pairs, 1)[0]\n",
      "        result = left_closest_pairs | right_closest_pairs  \n",
      "    \n",
      "    # merge part    \n",
      "    near_middle_indices = list()\n",
      "    for index in indices:\n",
      "        if abs(cluster_list[index].horiz_center() - mid_horiz_coordinate) <= min_distance:\n",
      "            near_middle_indices.append(index)    \n",
      "    \n",
      "    # sort list of indices for the near middle clusters by vertical direction\n",
      "    near_middle_indices.sort(key = lambda x: cluster_list[x].vert_order())\n",
      "    \n",
      "    for index1 in range(len(near_middle_indices) - 1):\n",
      "        for index2 in range(index1 + 1, min(index1 + 4, len(near_middle_indices))):\n",
      "            if min_distance == cluster_list[near_middle_indices[index1]].distance(cluster_list[near_middle_indices[index2]]):\n",
      "                result.add((min_distance, min(near_middle_indices[index1], near_middle_indices[index2]), \n",
      "                            max(near_middle_indices[index1], near_middle_indices[index2])))\n",
      "            elif min_distance > cluster_list[near_middle_indices[index1]].distance(cluster_list[near_middle_indices[index2]]):\n",
      "                min_distance = cluster_list[near_middle_indices[index1]].distance(cluster_list[near_middle_indices[index2]])\n",
      "                result = set()\n",
      "                result.add((min_distance, min(near_middle_indices[index1], near_middle_indices[index2]), \n",
      "                            max(near_middle_indices[index1], near_middle_indices[index2])))\n",
      "\n",
      "    return result\n",
      "\n",
      "def fast_closest_pair(cluster_list):\n",
      "    \"\"\"\n",
      "    Compute a closest pair of clusters in cluster_list\n",
      "    using O(n log(n)) divide and conquer algorithm\n",
      "    \n",
      "    Returns a tuple (distance, idx1, idx2) with idx1 < idx 2 where\n",
      "    cluster_list[idx1] and cluster_list[idx2]\n",
      "    have the smallest distance dist of any pair of clusters\n",
      "    \"\"\"\n",
      "        \n",
      "    def fast_helper(cluster_list, horiz_order, vert_order):\n",
      "        \"\"\"\n",
      "        Divide and conquer method for computing distance between closest pair of points\n",
      "        Running time is O(n * log(n))\n",
      "        \n",
      "        horiz_order and vert_order are lists of indices for clusters\n",
      "        ordered horizontally and vertically\n",
      "        \n",
      "        Returns a tuple (distance, idx1, idx2) with idx1 < idx 2 where\n",
      "        cluster_list[idx1] and cluster_list[idx2]\n",
      "        have the smallest distance dist of any pair of clusters\n",
      "    \n",
      "        \"\"\"\n",
      "        \n",
      "        # base case\n",
      "        if len(horiz_order) <= 3:\n",
      "            return random.sample(bf_closest_pair_indices(cluster_list, horiz_order), 1)[0]\n",
      "        \n",
      "        # divide\n",
      "        half_of_clusters = int(math.ceil(float(len(horiz_order)) / 2))\n",
      "        mid_horiz_coordinate = (cluster_list[horiz_order[half_of_clusters-1]].horiz_center() + cluster_list[horiz_order[half_of_clusters]].horiz_center())*0.5\n",
      "    \n",
      "        left_temp_horiz_order = set(horiz_order[:half_of_clusters])\n",
      "        right_temp_horiz_order = set(horiz_order[half_of_clusters:])\n",
      "        \n",
      "        left_temp_vert_order = filter(lambda x: x in left_temp_horiz_order, vert_order)\n",
      "        right_temp_vert_order = filter(lambda x: x in right_temp_horiz_order, vert_order)\n",
      "    \n",
      "        left_closest_pair = fast_helper(cluster_list, horiz_order[:half_of_clusters], left_temp_vert_order)\n",
      "        right_closest_pair = fast_helper(cluster_list, horiz_order[half_of_clusters:], right_temp_vert_order)   \n",
      "        \n",
      "        # choosing min in both halfes\n",
      "        if left_closest_pair[0] <= right_closest_pair[0]:\n",
      "            min_distance = left_closest_pair[0]\n",
      "            result = left_closest_pair\n",
      "        else:\n",
      "            min_distance = right_closest_pair[0]\n",
      "            result = right_closest_pair        \n",
      "        \n",
      "        # conquer\n",
      "        \n",
      "        near_middle_indices = filter(lambda x: abs(cluster_list[x].horiz_center() - mid_horiz_coordinate) <= min_distance, vert_order)\n",
      "    \n",
      "        for index1 in range(len(near_middle_indices) - 1):\n",
      "            for index2 in range(index1 + 1, min(index1 + 4, len(near_middle_indices))):\n",
      "                if min_distance > cluster_list[near_middle_indices[index1]].distance(cluster_list[near_middle_indices[index2]]):\n",
      "                    min_distance = cluster_list[near_middle_indices[index1]].distance(cluster_list[near_middle_indices[index2]])\n",
      "                    result = (min_distance, min(near_middle_indices[index1], near_middle_indices[index2]), \n",
      "                              max(near_middle_indices[index1], near_middle_indices[index2]))\n",
      "    \n",
      "        return result\n",
      "            \n",
      "    # compute list of indices for the clusters ordered in the horizontal direction\n",
      "    hcoord_and_index = [(cluster_list[idx].horiz_center(), idx) \n",
      "                        for idx in range(len(cluster_list))]    \n",
      "    hcoord_and_index.sort()\n",
      "    horiz_order = [hcoord_and_index[idx][1] for idx in range(len(hcoord_and_index))]\n",
      "     \n",
      "    # compute list of indices for the clusters ordered in vertical direction\n",
      "    vcoord_and_index = [(cluster_list[idx].vert_center(), idx) \n",
      "                        for idx in range(len(cluster_list))]    \n",
      "    vcoord_and_index.sort()\n",
      "    vert_order = [vcoord_and_index[idx][1] for idx in range(len(vcoord_and_index))]\n",
      "\n",
      "    # compute answer recursively\n",
      "    answer = fast_helper(cluster_list, horiz_order, vert_order)\n",
      "    return (answer[0], min(answer[1:]), max(answer[1:]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIRECTORY = \"http://commondatastorage.googleapis.com/codeskulptor-assets/\"\n",
      "DATA_3108_URL = DIRECTORY + \"data_clustering/unifiedCancerData_3108.csv\"\n",
      "DATA_896_URL = DIRECTORY + \"data_clustering/unifiedCancerData_896.csv\"\n",
      "DATA_290_URL = DIRECTORY + \"data_clustering/unifiedCancerData_290.csv\"\n",
      "DATA_111_URL = DIRECTORY + \"data_clustering/unifiedCancerData_111.csv\"\n",
      "\n",
      "\n",
      "def load_data_table(data_url):\n",
      "    \"\"\"\n",
      "    Import a table of county-based cancer risk data\n",
      "    from a csv format file\n",
      "    \"\"\"\n",
      "    data_file = urllib2.urlopen(data_url)\n",
      "    data = data_file.read()\n",
      "    data_lines = data.split('\\n')\n",
      "    print \"Loaded\", len(data_lines), \"data points\"\n",
      "    data_tokens = [line.split(',') for line in data_lines]\n",
      "    return [Cluster(tokens[0], float(tokens[1]), float(tokens[2]), int(tokens[3]), float(tokens[4])) \n",
      "            for tokens in data_tokens]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST_CLUSTERS = load_data_table(DATA_111_URL)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded 111 data points\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hierarchical_clustering(cluster_list, num_clusters):\n",
      "    \"\"\"\n",
      "    Compute a hierarchical clustering of a set of clusters\n",
      "    Note: the function mutates cluster_list\n",
      "    \n",
      "    Input: List of clusters, number of clusters\n",
      "    Output: List of clusters whose length is num_clusters\n",
      "    \"\"\"\n",
      "    while len(cluster_list) > num_clusters:\n",
      "        closest_pair = fast_closest_pair(cluster_list)\n",
      "        new_cluster = cluster_list.pop(closest_pair[1]).merge_clusters(cluster_list.pop(closest_pair[2]))\n",
      "        cluster_list.append(new_cluster)\n",
      "    return cluster_list\n",
      "    \n",
      "def kmeans_clustering(cluster_list, num_clusters, num_iterations):\n",
      "    \"\"\"\n",
      "    Compute the k-means clustering of a set of clusters\n",
      "    \n",
      "    Input: List of clusters, number of clusters, number of iterations\n",
      "    Output: List of clusters whose length is num_clusters\n",
      "    \"\"\"\n",
      "    \n",
      "    # initialize k-means clusters to be initial clusters with largest populations\n",
      "\n",
      "    return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([(1.266216002018164, 94, 105)])\n",
        "(1.266216002018164, 94, 105)\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1.0, 0, 1)\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}